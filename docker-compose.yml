# UALFlix - Docker Compose CORRIGIDO - Problema da Base de Dados Resolvido

services:
  # ================================================================
  # DATABASE - SIMPLIFICADO E CORRIGIDO
  # ================================================================
  
  # DATABASE MASTER - Principal
  ualflix_db_master:
    image: postgres:13
    container_name: ualflix_db_master
    environment:
      POSTGRES_DB: ualflix
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_HOST_AUTH_METHOD: trust  # Simplifica autenticação
    volumes:
      - db_master_data:/var/lib/postgresql/data
      - ./database/init_master.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    ports:
      - "5432:5432"
    networks:
      - ualflix_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ualflix"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

      # DATABASE SLAVE - Réplica para leituras
  ualflix_db_slave:
    image: postgres:13
    container_name: ualflix_db_slave
    environment:
      POSTGRES_DB: ualflix
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_MASTER_HOST: ualflix_db_master
      POSTGRES_MASTER_PORT: 5432
      PGUSER: postgres
    volumes:
      - db_slave_data:/var/lib/postgresql/data
      - ./database/setup_slave.sh:/docker-entrypoint-initdb.d/setup_slave.sh:ro
    ports:
      - "5433:5432"
    networks:
      - ualflix_network
    depends_on:
      ualflix_db_master:
        condition: service_healthy
    command: |
      bash -c "
        # Aguardar master estar pronto
        until pg_isready -h ualflix_db_master -p 5432 -U postgres; do
          echo 'Aguardando master...'
          sleep 2
        done
        
        # Se é primeira vez, fazer backup do master
        if [ ! -f /var/lib/postgresql/data/standby.signal ]; then
          rm -rf /var/lib/postgresql/data/*
          pg_basebackup -h ualflix_db_master -D /var/lib/postgresql/data -U postgres -v -P -W
          echo 'standby_mode = on' >> /var/lib/postgresql/data/recovery.conf
          echo 'primary_conninfo = \"host=ualflix_db_master port=5432 user=postgres\"' >> /var/lib/postgresql/data/recovery.conf
          echo 'trigger_file = \"/tmp/promote_to_master\"' >> /var/lib/postgresql/data/recovery.conf
          touch /var/lib/postgresql/data/standby.signal
        fi
        
        # Iniciar PostgreSQL em modo slave
        docker-entrypoint.sh postgres
      "
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped


  # ================================================================
  # MESSAGING QUEUE
  # ================================================================
  
  queue_service:
    image: rabbitmq:3-management
    container_name: ualflix_queue
    networks:
      - ualflix_network
    ports:
      - "5672:5672"
      - "15672:15672"
      - "15692:15692"
    environment:
      - RABBITMQ_DEFAULT_USER=ualflix
      - RABBITMQ_DEFAULT_PASS=ualflix_password
      - RABBITMQ_ENABLED_PLUGINS_FILE=/etc/rabbitmq/enabled_plugins
    command: >
      bash -c "
        echo '[rabbitmq_management,rabbitmq_prometheus].' > /etc/rabbitmq/enabled_plugins &&
        rabbitmq-server
      "
    healthcheck:
      test: rabbitmq-diagnostics -q ping
      interval: 30s
      timeout: 30s
      retries: 3
    restart: unless-stopped

  # ================================================================
  # MICROSERVICES
  # ================================================================

  # Authentication Service
  authentication_service:
    build: ./authentication_service
    container_name: ualflix_auth
    environment:
      - SECRET_KEY=ualflix-secret-key-change-in-production
      - DB_MASTER_HOST=ualflix_db_master
      - DB_SLAVE_HOST=ualflix_db_master  # Usar mesmo DB para simplificar
      - DB_NAME=ualflix
      - DB_USER=postgres
      - DB_PASSWORD=password
    networks:
      - ualflix_network
    depends_on:
      ualflix_db_master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Catalog Service
  catalog_service:
    build: ./catalog_service
    container_name: ualflix_catalog
    environment:
      - QUEUE_HOST=queue_service
      - QUEUE_USER=ualflix
      - QUEUE_PASSWORD=ualflix_password
      - AUTH_SERVICE_URL=http://authentication_service:8000
      - DB_MASTER_HOST=ualflix_db_master
      - DB_SLAVE_HOST=ualflix_db_master  # Usar mesmo DB para simplificar
      - DB_NAME=ualflix
      - DB_USER=postgres
      - DB_PASSWORD=password
    networks:
      - ualflix_network
    volumes:
      - video_storage:/videos
    depends_on:
      ualflix_db_master:
        condition: service_healthy
      queue_service:
        condition: service_healthy
      authentication_service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Streaming Service
  streaming_service:
    build: ./streaming_service
    container_name: ualflix_streaming
    volumes:
      - video_storage:/videos
    networks:
      - ualflix_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Video Processor
  video_processor:
    build: ./video_processor
    container_name: ualflix_processor
    environment:
      - QUEUE_HOST=queue_service
      - QUEUE_USER=ualflix
      - QUEUE_PASSWORD=ualflix_password
    networks:
      - ualflix_network
    volumes:
      - video_storage:/videos
    depends_on:
      queue_service:
        condition: service_healthy
    restart: unless-stopped

  # Admin Service - Métricas automáticas
  admin_service:
    build: ./admin_service
    container_name: ualflix_admin
    networks:
      - ualflix_network
    depends_on:
      - authentication_service
      - catalog_service
      - streaming_service
      - video_processor
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # ================================================================
  # FRONTEND
  # ================================================================

  frontend:
    build: ./frontend
    container_name: ualflix_frontend
    networks:
      - ualflix_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # ================================================================
  # LOAD BALANCER & PROXY
  # ================================================================

  # Nginx Reverse Proxy
  nginx:
    image: nginx:latest
    container_name: ualflix_nginx
    ports:
      - "8080:8080"
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
      - video_storage:/videos
    depends_on:
      frontend:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      grafana:
        condition: service_healthy
    networks:
      - ualflix_network
    restart: unless-stopped

  # ================================================================
  # MONITORING & METRICS (FUNCIONALIDADE 7)
  # ================================================================

  # Prometheus - Coleta de métricas
  prometheus:
    image: prom/prometheus:latest
    container_name: ualflix_prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alert.rules:/etc/prometheus/alert.rules
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - ualflix_network
    depends_on:
      - catalog_service
      - streaming_service
      - video_processor
      - admin_service
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--query.max-concurrency=20'
      - '--query.timeout=2m'
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Grafana - Dashboards de métricas
  grafana:
    image: grafana/grafana:latest
    container_name: ualflix_grafana
    ports:
      - "4000:4000"
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - ualflix_network
    depends_on:
      prometheus:
        condition: service_healthy
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SERVER_HTTP_PORT=4000
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:4000/api/health || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 3
    restart: unless-stopped

# ================================================================
# VOLUMES
# ================================================================

volumes:
  # Database volume
  db_master_data:
    driver: local
  db_slave_data:
    driver: local
  
  # Application volumes
  video_storage:
    driver: local
  
  # Monitoring volumes
  grafana_data:
    driver: local
  prometheus_data:
    driver: local

# ================================================================
# NETWORKS
# ================================================================

networks:
  ualflix_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16